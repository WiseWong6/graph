/**
 * å‘é‡ç´¢å¼•æ„å»ºè„šæœ¬
 *
 * ä¸ºé‡‘å¥åº“ã€æ–‡ç« åº“å»ºç«‹å‘é‡ç´¢å¼•
 *
 * ä½¿ç”¨æ–¹å¼:
 *   npm run build-indices
 */

import {
  VectorStoreIndex,
  Document,
  storageContextFromDefaults,
  Settings
} from "llamaindex";
import { LanceDBVectorStore } from "../src/rag/vector-store/lancedb";
import { HuggingFaceEmbedding } from "@llamaindex/huggingface";
import { readFileSync, readdirSync, mkdirSync, existsSync, writeFileSync } from "fs";
import { join, resolve } from "path";

const DATA_DIR = join(process.cwd(), "data");
const INDICES_DIR = join(process.cwd(), ".index");

// å…¨å±€è®¾ç½®åµŒå…¥æ¨¡å‹ - ä½¿ç”¨æœ¬åœ°æ¨¡å‹è·¯å¾„
Settings.embedModel = new HuggingFaceEmbedding({
  modelType: resolve(process.cwd(), "local_models")  // å¼ºåˆ¶ä½¿ç”¨æœ¬åœ°æ¨¡å‹
});

/**
 * åŠ è½½ JSONL æ–‡ä»¶
 */
function loadJSONL(filePath: string): any[] {
  const content = readFileSync(filePath, "utf-8");
  const lines = content.split("\n").filter(line => line.trim());

  return lines.map(line => {
    try {
      return JSON.parse(line);
    } catch {
      return null;
    }
  }).filter(item => item !== null);
}

function parseNumberArg(args: string[], name: string, fallback: number): number {
  const idx = args.indexOf(name);
  if (idx === -1) return fallback;
  const value = args[idx + 1];
  const parsed = Number(value);
  return Number.isFinite(parsed) && parsed > 0 ? parsed : fallback;
}

function formatDurationMs(ms: number): string {
  if (!Number.isFinite(ms) || ms <= 0) return "0s";
  const seconds = Math.round(ms / 1000);
  if (seconds < 60) return `${seconds}s`;
  const minutes = Math.floor(seconds / 60);
  const remain = seconds % 60;
  return `${minutes}m${remain}s`;
}

/**
 * é€šç”¨åˆ†æ‰¹æ„å»ºç´¢å¼•å‡½æ•°
 */
async function buildIndexInBatches(
  name: string,
  items: any[],
  batchSize: number,
  outputDir: string,
  docMapper: (item: any) => Document,
  options?: { chunkSize?: number; concurrency?: number; persistEveryChunks?: number }
): Promise<void> {
  if (items.length === 0) {
    console.log(`[build-indices] âš ï¸  ${name}: æ— æ•°æ®ï¼Œè·³è¿‡`);
    return;
  }

  // åˆ›å»ºè¾“å‡ºç›®å½•
  mkdirSync(outputDir, { recursive: true });

  const chunkSize = options?.chunkSize ?? 10;
  const concurrency = options?.concurrency ?? 1;
  const persistEveryChunks = options?.persistEveryChunks ?? Math.ceil(batchSize / chunkSize);
  const docStorePath = join(outputDir, "doc_store.json");
  const indexStorePath = join(outputDir, "index_store.json");
  const lanceDbUri = join(outputDir, "lancedb");
  
  // å†³å®šè¡¨åï¼šæ ¹æ® name æˆ– outputDir æ¨æ–­
  const tableName = name === "é‡‘å¥åº“" ? "quotes" : "articles";

  // åˆå§‹åŒ– LanceDB å‘é‡å­˜å‚¨
  const vectorStore = new LanceDBVectorStore({
    uri: lanceDbUri,
    tableName: tableName
  });
  
  // ç¡®ä¿ LanceDB åˆå§‹åŒ–
  await vectorStore.init();

  let storageContext: Awaited<ReturnType<typeof storageContextFromDefaults>>;
  try {
    storageContext = await storageContextFromDefaults({
      persistDir: outputDir,
      vectorStore: vectorStore
    });
  } catch (e) {
    console.error(`[build-indices] âŒ æ— æ³•åŠ è½½ç´¢å¼•å­˜å‚¨: ${e}`);
    throw e;
  }

  // å…³é—­è‡ªåŠ¨æŒä¹…åŒ– (æˆ‘ä»¬è‡ªå·±æ§åˆ¶)
  const docStoreAny = storageContext.docStore as any;
  if (docStoreAny?.kvStore) docStoreAny.kvStore.persistPath = undefined;
  const indexStoreAny = storageContext.indexStore as any;
  if (indexStoreAny?.kvStore) indexStoreAny.kvStore.persistPath = undefined;
  // LanceDB ä¸éœ€è¦ persistPathï¼Œå®ƒè‡ªå·±ç®¡ç†

  // ===== 1. åŠ è½½å·²æœ‰ç´¢å¼•å¹¶å»ºç«‹ ID Set (å»é‡é€»è¾‘) =====
  let existingIds = new Set<string>();
  let index: VectorStoreIndex | null = null;

  try {
    // å°è¯•åŠ è½½ç°æœ‰ç´¢å¼•
    // æ³¨æ„ï¼šå¦‚æœæ˜¯ LanceDBï¼Œæˆ‘ä»¬éœ€è¦æ£€æŸ¥è¡¨é‡Œæ˜¯å¦æœ‰æ•°æ®
    // æˆ‘ä»¬ä¸èƒ½åªä¾èµ– vector_store.json æ˜¯å¦å­˜åœ¨
    
    console.log(`[build-indices]   ğŸ“š å°è¯•åŠ è½½ç°æœ‰ç´¢å¼•...`);
    
    // å¦‚æœæ˜¯ LanceDBï¼Œinit ä¼šè‡ªåŠ¨è¿æ¥æ•°æ®åº“
    // VectorStoreIndex.fromStorageContext åœ¨æŸäº›ç‰ˆæœ¬ä¸­å¯èƒ½ä¸å­˜åœ¨ï¼Œä½¿ç”¨ init
    index = await VectorStoreIndex.init({
      storageContext
    });
    
    // æå–æ‰€æœ‰å·²å­˜åœ¨çš„ docId
    // æ–¹æ³• 1: ä» docStore è·å– (å¦‚æœæœ‰)
    const docs = await storageContext.docStore.docs();
    Object.keys(docs).forEach(id => existingIds.add(id));
    
    // æ–¹æ³• 2: ä» LanceDB è·å– (æ›´å‡†ç¡®ï¼Œå› ä¸ºæœ‰äº›å¯èƒ½åªåœ¨ vectorStore é‡Œ)
    if (vectorStore instanceof LanceDBVectorStore) {
      console.log(`[build-indices]   ğŸ” ä» LanceDB æ‰«æå·²å­˜åœ¨çš„ ID...`);
      const dbIds = await vectorStore.getAllRefDocIds();
      dbIds.forEach(id => existingIds.add(id));
    }
    
    console.log(`[build-indices]   âœ… å·²åŠ è½½ ${existingIds.size} æ¡å†å²æ•°æ®ï¼Œå°†è·³è¿‡é‡å¤é¡¹`);
  } catch (e) {
    console.log(`[build-indices]   âš ï¸ åŠ è½½ç°æœ‰ç´¢å¼•å¤±è´¥ (å¯èƒ½æ˜¯é¦–æ¬¡æ„å»º): ${e}`);
    index = null;
    existingIds.clear();
  }

  const totalBatches = Math.ceil(items.length / batchSize);
  console.log(`[build-indices] ${name}: å…± ${items.length} æ¡ï¼Œåˆ† ${totalBatches} æ‰¹å¤„ç† (æ¯æ‰¹ ${batchSize})`);
  console.log(`[build-indices] ${name}: chunkSize=${chunkSize}, concurrency=${concurrency}, persistEveryChunks=${persistEveryChunks}`);

  let insertedTotal = 0;
  const globalStart = Date.now();

  // ===== 2. åˆ†æ‰¹å¤„ç† =====
  for (let i = 0; i < items.length; i += batchSize) {
    const currentBatchNum = Math.floor(i / batchSize) + 1;
    const batchItems = items.slice(i, i + batchSize);
    
    // è½¬æ¢ä¸º Document (æ­¤æ—¶ç”Ÿæˆ ID)
    const docs = batchItems.map(docMapper);
    
    // è¿‡æ»¤æ‰å·²å­˜åœ¨çš„æ–‡æ¡£
    const newDocs = docs.filter(doc => !existingIds.has(doc.id_));
    const skippedCount = docs.length - newDocs.length;
    
    if (newDocs.length === 0) {
      console.log(`[build-indices]   â­ï¸ ç¬¬ ${currentBatchNum}/${totalBatches} æ‰¹: å…¨éƒ¨ ${docs.length} æ¡å·²å­˜åœ¨ï¼Œè·³è¿‡`);
      continue;
    }
    
    if (skippedCount > 0) {
      console.log(`[build-indices]   â„¹ï¸ ç¬¬ ${currentBatchNum}/${totalBatches} æ‰¹: å‘ç° ${skippedCount} æ¡é‡å¤ï¼Œä»…å¤„ç†æ–°å¢çš„ ${newDocs.length} æ¡...`);
    } else {
      console.log(`[build-indices]   æ­£åœ¨å¤„ç†ç¬¬ ${currentBatchNum}/${totalBatches} æ‰¹ (æ–°å¢ ${newDocs.length}/${docs.length} æ¡)...`);
    }

    const batchStart = Date.now();

    let createdIndexThisBatch = false;
    let processedInBatch = 0;

    if (!index) {
      console.log(`[build-indices]   ğŸš€ åˆå§‹åŒ–ç´¢å¼•...`);
      const initialDocs = newDocs.slice(0, Math.min(chunkSize, newDocs.length));
      index = await VectorStoreIndex.fromDocuments(initialDocs, {
        storageContext
      });
      insertedTotal += initialDocs.length;
      for (const d of initialDocs) existingIds.add(d.id_);
      processedInBatch += initialDocs.length;
      createdIndexThisBatch = true;
    }

    const docsToInsert = createdIndexThisBatch ? newDocs.slice(Math.min(chunkSize, newDocs.length)) : newDocs;

    const totalChunks = Math.ceil(docsToInsert.length / chunkSize);
    let avgPerDocMs = 0;
    let completedDocsInBatch = processedInBatch;

    for (let chunkIdx = 0; chunkIdx < totalChunks; chunkIdx++) {
      const start = chunkIdx * chunkSize;
      const chunk = docsToInsert.slice(start, start + chunkSize);
      const chunkStart = Date.now();

      try {
        await storageContext.docStore.addDocuments(chunk, true);
        for (const doc of chunk) {
          await storageContext.docStore.setDocumentHash(doc.id_, doc.hash);
        }

        const nodes = await Settings.nodeParser.getNodesFromDocuments(chunk);
        await index!.insertNodes(nodes);
        insertedTotal += chunk.length;
        for (const doc of chunk) existingIds.add(doc.id_);
      } catch (err) {
        console.error(`[build-indices]   âŒ æ’å…¥æ‰¹æ¬¡å¤±è´¥ (chunkIdx=${chunkIdx}, size=${chunk.length}):`, err);
      }

      const chunkElapsed = Date.now() - chunkStart;
      const perDoc = chunkElapsed / Math.max(1, chunk.length);
      avgPerDocMs = avgPerDocMs === 0 ? perDoc : avgPerDocMs * 0.8 + perDoc * 0.2;

      completedDocsInBatch += chunk.length;

      const remainingInBatch = newDocs.length - completedDocsInBatch;
      const etaMs = avgPerDocMs * remainingInBatch;
      const elapsedTotal = Date.now() - globalStart;

      process.stdout.write(
        `\r[build-indices]   æ‰¹ ${currentBatchNum}/${totalBatches} Â· ${completedDocsInBatch}/${newDocs.length} Â· æ€»æ’å…¥ ${insertedTotal} Â· æœ¬æ‰¹ETA ${formatDurationMs(etaMs)} Â· æ€»è€—æ—¶ ${formatDurationMs(elapsedTotal)}        `
      );

      if ((chunkIdx + 1) % persistEveryChunks === 0 || chunkIdx === totalChunks - 1) {
        if (docStoreAny?.kvStore?.persist) {
          await docStoreAny.kvStore.persist(docStorePath);
        } else {
          await storageContext.docStore.persist(docStorePath);
        }
        if (indexStoreAny?.kvStore?.persist) {
          await indexStoreAny.kvStore.persist(indexStorePath);
        } else {
          await storageContext.indexStore.persist(indexStorePath);
        }
        // LanceDB ä¸éœ€è¦æ‰‹åŠ¨ persist
      }
    }

    if (totalChunks === 0) {
      if (docStoreAny?.kvStore?.persist) {
        await docStoreAny.kvStore.persist(docStorePath);
      } else {
        await storageContext.docStore.persist(docStorePath);
      }
      if (indexStoreAny?.kvStore?.persist) {
        await indexStoreAny.kvStore.persist(indexStorePath);
      } else {
        await storageContext.indexStore.persist(indexStorePath);
      }
      // LanceDB ä¸éœ€è¦æ‰‹åŠ¨ persist
    }

    process.stdout.write("\n");
    console.log(`[build-indices]   âœ… ç¬¬ ${currentBatchNum} æ‰¹å®Œæˆ (è€—æ—¶: ${formatDurationMs(Date.now() - batchStart)})`);
    
    // æ‰‹åŠ¨è§¦å‘åƒåœ¾å›æ”¶ (å¦‚æœå¯ç”¨)
    if (global.gc) {
        global.gc();
    }
  }
  
  // ç¡®ä¿æœ€åä¿å­˜
  // åœ¨æŸäº›ç‰ˆæœ¬ä¸­éœ€è¦æ˜¾å¼è°ƒç”¨ï¼Œä½† storageContextFromDefaults ç»‘å®šçš„æ–‡ä»¶ç³»ç»Ÿé€šå¸¸ä¼šåœ¨æ›´æ–°æ—¶å†™å…¥
  // æˆ–è€… index å¯¹è±¡æœ‰ persist æ–¹æ³•? 
  // index.storageContext.docStore.persist()
  // ç®€å•èµ·è§ï¼Œæˆ‘ä»¬ä¿¡ä»»åº“çš„è¡Œä¸ºã€‚
  console.log(`[build-indices] âœ… ${name} ç´¢å¼•æ„å»ºå®Œæˆï¼Œå·²ä¿å­˜è‡³: ${outputDir}`);
}

/**
 * æ„å»ºé‡‘å¥åº“ç´¢å¼•
 */
async function buildQuotesIndex(options?: { chunkSize?: number; concurrency?: number; persistEveryChunks?: number }): Promise<void> {
  console.log("\n[build-indices] === æ„å»ºé‡‘å¥åº“ç´¢å¼• ===");

  const jsonlFile = join(DATA_DIR, "golden_sentences.jsonl");
  if (!existsSync(jsonlFile)) {
    console.error(`[build-indices] âŒ æ–‡ä»¶ä¸å­˜åœ¨: ${jsonlFile}`);
    return;
  }

  const data = loadJSONL(jsonlFile);
  const outputDir = join(INDICES_DIR, "golden_quotes");

  await buildIndexInBatches(
    "é‡‘å¥åº“",
    data,
    1000,
    outputDir,
    (item) => {
      // å…³é”®ä¿®å¤ï¼šåœ¨ metadata ä¸­ä¿ç•™åŸå§‹ content
      const doc = new Document({
        text: item.content,
        metadata: {
          content: item.content,  // ä¿ç•™åŸå§‹å†…å®¹
          id: item.id,
          quote_type: item.quote_type || "",
          quality_score: item.quality_score?.overall || 0,
          source_title: item.source_title || "",
          url: item.source_url || "",
          category: item.category || ""
        }
      });
      if (item.id) doc.id_ = String(item.id);
      return doc;
    },
    options
  );
}

/**
 * æ„å»ºæ–‡ç« åº“ç´¢å¼•
 */
async function buildArticlesIndex(options?: { chunkSize?: number; concurrency?: number; persistEveryChunks?: number }): Promise<void> {
  console.log("\n[build-indices] === æ„å»ºæ–‡ç« åº“ç´¢å¼• ===");

  const articlesDir = join(DATA_DIR, "articles");
  if (!existsSync(articlesDir)) {
    console.error(`[build-indices] âŒ ç›®å½•ä¸å­˜åœ¨: ${articlesDir}`);
    return;
  }

  const files = readdirSync(articlesDir).filter(f => f.endsWith(".jsonl"));
  if (files.length === 0) {
    console.error(`[build-indices] âŒ æœªæ‰¾åˆ° JSONL æ–‡ä»¶`);
    return;
  }

  console.log(`[build-indices] åŠ è½½ ${files.length} ä¸ªæ–‡ä»¶...`);
  
  let allArticles: any[] = [];
  for (const file of files) {
    const filePath = join(articlesDir, file);
    const articles = loadJSONL(filePath);
    // é™„åŠ æºæ–‡ä»¶ååˆ°æ¯ä¸ªæ–‡ç« å¯¹è±¡ï¼Œä»¥ä¾¿åœ¨ mapper ä¸­ä½¿ç”¨
    articles.forEach(a => a._source_file = file);
    allArticles.push(...articles);
  }

  const outputDir = join(INDICES_DIR, "articles");

  await buildIndexInBatches(
    "æ–‡ç« åº“",
    allArticles,
    500,
    outputDir,
    (item) => {
      const text = `æ ‡é¢˜ï¼š${item.title}\n\n${item.content}`;
      // å‡å°‘ metadata ä»¥èŠ‚çœç©ºé—´
      // æ³¨æ„ï¼šSimpleVectorStore ä¼šæŠŠ metadata ä¹Ÿå­˜å…¥ JSONï¼Œå¯¹äºå‡ ä¸‡ç¯‡æ–‡ç« ï¼Œè¿™ä¼šéå¸¸å¤§
      // æˆ‘ä»¬åªä¿ç•™æœ€å…³é”®çš„ title å’Œ urlï¼Œå…¶ä»–å¯ä»¥å»æ‰
      const minimalMetadata = {
        title: item.title || "",
        url: item.url || "",
        // source_file: item._source_file || "", // æš‚ä¸”ç§»é™¤ä»¥å‡å°ä½“ç§¯
        // publish_time: item.publish_time || "" // æš‚ä¸”ç§»é™¤ä»¥å‡å°ä½“ç§¯
      };
      
      const doc = new Document({
        text,
        metadata: minimalMetadata
      });
      // ä½¿ç”¨ URL æˆ– æ ‡é¢˜+æ–‡ä»¶å ä½œä¸ºç¡®å®šæ€§ ID
      if (item.url) {
        doc.id_ = item.url;
      } else {
        const cleanTitle = (item.title || "").replace(/[^a-zA-Z0-9\u4e00-\u9fa5]/g, "");
        const cleanSource = (item._source_file || "").replace(/[^a-zA-Z0-9]/g, "");
        doc.id_ = `${cleanTitle}_${cleanSource}`;
      }
      return doc;
    },
    options
  );
}

/**
 * æ„å»ºæ ‡é¢˜åº“ç´¢å¼• (ç”Ÿæˆ JSONL æ–‡ä»¶)
 */
async function buildTitlesIndex(): Promise<void> {
  console.log("\n[build-indices] === æ„å»ºæ ‡é¢˜åº“ (ç”Ÿæˆ article_titles.jsonl) ===");

  const articlesDir = join(DATA_DIR, "articles");
  if (!existsSync(articlesDir)) {
    console.error(`[build-indices] âŒ ç›®å½•ä¸å­˜åœ¨: ${articlesDir}`);
    return;
  }

  const files = readdirSync(articlesDir).filter(f => f.endsWith(".jsonl"));
  if (files.length === 0) {
    console.error(`[build-indices] âŒ æœªæ‰¾åˆ° JSONL æ–‡ä»¶`);
    return;
  }

  let titleCount = 0;
  const titleLines: string[] = [];

  for (const file of files) {
    const filePath = join(articlesDir, file);
    const articles = loadJSONL(filePath);

    for (const article of articles) {
      if (!article.title) continue;

      const titleRecord = {
        title: article.title,
        source_file: file
      };
      
      titleLines.push(JSON.stringify(titleRecord));
      titleCount++;
    }
  }

  const outputFile = join(DATA_DIR, "article_titles.jsonl");
  writeFileSync(outputFile, titleLines.join("\n"), "utf-8");

  console.log(`[build-indices] âœ… æ ‡é¢˜åº“ç”Ÿæˆå®Œæˆ: ${titleCount} æ¡è®°å½•`);
  console.log(`[build-indices]    å·²ä¿å­˜è‡³: ${outputFile}`);
}

/**
 * ä¸»å‡½æ•°
 */
async function main() {
  const args = process.argv.slice(2);
  const target = args.find(a => !a.startsWith("-")); // 'quotes' | 'articles' | 'titles' | undefined
  const chunkSize = parseNumberArg(args, "--chunk", 10);
  const concurrency = parseNumberArg(args, "--concurrency", 1);
  const persistEveryChunks = args.includes("--persist-every") ? parseNumberArg(args, "--persist-every", 1) : undefined;
  const runtimeOptions: { chunkSize?: number; concurrency?: number; persistEveryChunks?: number } = {
    chunkSize,
    concurrency,
    persistEveryChunks
  };

  console.log("[build-indices] å¼€å§‹æ„å»ºå‘é‡ç´¢å¼•...\n");
  console.log(`[build-indices] æ•°æ®ç›®å½•: ${DATA_DIR}`);
  console.log(`[build-indices] ç´¢å¼•ç›®å½•: ${INDICES_DIR}`);
  console.log(`[build-indices] åµŒå…¥æ¨¡å‹: æœ¬åœ°æ¨¡å‹ (local_models)`);
  if (target) {
    console.log(`[build-indices] ğŸ¯ ä»…æ„å»ºç›®æ ‡: ${target}`);
  }

  const startTime = Date.now();

  try {
    // æ„å»ºé‡‘å¥åº“ç´¢å¼•
    if (!target || target === 'quotes') {
      await buildQuotesIndex(runtimeOptions);
    }

    // æ„å»ºæ–‡ç« åº“ç´¢å¼•
    if (!target || target === 'articles') {
      await buildArticlesIndex(runtimeOptions);
    }

    // æ„å»ºæ ‡é¢˜åº“ç´¢å¼• (éå‘é‡ï¼Œä»…ç”Ÿæˆ JSONL)
    if (!target || target === 'titles') {
      await buildTitlesIndex();
    }

    const elapsed = ((Date.now() - startTime) / 1000).toFixed(1);
    console.log(`\n[build-indices] ğŸ‰ ç´¢å¼•æ„å»ºå®Œæˆ! (æ€»è€—æ—¶: ${elapsed}ç§’)`);

  } catch (error) {
    console.error(`\n[build-indices] âŒ æ„å»ºå¤±è´¥:`, error);
    process.exit(1);
  }
}

// è¿è¡Œ
main();
