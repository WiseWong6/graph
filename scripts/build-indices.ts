/**
 * å‘é‡ç´¢å¼•æ„å»ºè„šæœ¬
 *
 * ä¸ºé‡‘å¥åº“ã€æ–‡ç« åº“å»ºç«‹å‘é‡ç´¢å¼•
 *
 * ä½¿ç”¨æ–¹å¼:
 *   npm run build-indices
 */

import {
  VectorStoreIndex,
  Document,
  storageContextFromDefaults,
  Settings
} from "llamaindex";
import { HuggingFaceEmbedding } from "@llamaindex/huggingface";
import { readFileSync, readdirSync, mkdirSync, existsSync, writeFileSync } from "fs";
import { join, resolve } from "path";

const DATA_DIR = join(process.cwd(), "data");
const INDICES_DIR = join(process.cwd(), ".index");

// å…¨å±€è®¾ç½®åµŒå…¥æ¨¡å‹ - ä½¿ç”¨æœ¬åœ°æ¨¡å‹è·¯å¾„
Settings.embedModel = new HuggingFaceEmbedding({
  modelType: resolve(process.cwd(), "local_models")  // å¼ºåˆ¶ä½¿ç”¨æœ¬åœ°æ¨¡å‹
});

/**
 * åŠ è½½ JSONL æ–‡ä»¶
 */
function loadJSONL(filePath: string): any[] {
  const content = readFileSync(filePath, "utf-8");
  const lines = content.split("\n").filter(line => line.trim());

  return lines.map(line => {
    try {
      return JSON.parse(line);
    } catch {
      return null;
    }
  }).filter(item => item !== null);
}

function parseNumberArg(args: string[], name: string, fallback: number): number {
  const idx = args.indexOf(name);
  if (idx === -1) return fallback;
  const value = args[idx + 1];
  const parsed = Number(value);
  return Number.isFinite(parsed) && parsed > 0 ? parsed : fallback;
}

function formatDurationMs(ms: number): string {
  if (!Number.isFinite(ms) || ms <= 0) return "0s";
  const seconds = Math.round(ms / 1000);
  if (seconds < 60) return `${seconds}s`;
  const minutes = Math.floor(seconds / 60);
  const remain = seconds % 60;
  return `${minutes}m${remain}s`;
}

/**
 * é€šç”¨åˆ†æ‰¹æ„å»ºç´¢å¼•å‡½æ•°
 */
async function buildIndexInBatches(
  name: string,
  items: any[],
  batchSize: number,
  outputDir: string,
  docMapper: (item: any) => Document,
  options?: { chunkSize?: number; concurrency?: number; persistEveryChunks?: number }
): Promise<void> {
  if (items.length === 0) {
    console.log(`[build-indices] âš ï¸  ${name}: æ— æ•°æ®ï¼Œè·³è¿‡`);
    return;
  }

  // åˆ›å»ºè¾“å‡ºç›®å½•
  mkdirSync(outputDir, { recursive: true });

  const chunkSize = options?.chunkSize ?? 10;
  const concurrency = options?.concurrency ?? 1;
  const persistEveryChunks = options?.persistEveryChunks ?? Math.ceil(batchSize / chunkSize);
  const docStorePath = join(outputDir, "doc_store.json");
  const indexStorePath = join(outputDir, "index_store.json");
  const vectorStorePath = join(outputDir, "vector_store.json");

  let storageContext: Awaited<ReturnType<typeof storageContextFromDefaults>>;
  try {
    storageContext = await storageContextFromDefaults({
      persistDir: outputDir
    });
  } catch (e) {
    console.error(`[build-indices] âŒ æ— æ³•åŠ è½½ç´¢å¼•å­˜å‚¨ (å¯èƒ½æ˜¯ JSON æŸå): ${e}`);
    console.error(`[build-indices]    è¯·åˆ é™¤ç›®å½•åé‡è¯•: ${outputDir}`);
    throw e;
  }

  const docStoreAny = storageContext.docStore as any;
  if (docStoreAny?.kvStore) docStoreAny.kvStore.persistPath = undefined;
  const indexStoreAny = storageContext.indexStore as any;
  if (indexStoreAny?.kvStore) indexStoreAny.kvStore.persistPath = undefined;
  const vectorStoresAny = storageContext.vectorStores as any;
  const vectorStoreAny = Object.values(vectorStoresAny)[0] as any;
  if (vectorStoreAny) vectorStoreAny.persistPath = undefined;

  // ===== 1. åŠ è½½å·²æœ‰ç´¢å¼•å¹¶å»ºç«‹ ID Set (å»é‡é€»è¾‘) =====
  let existingIds = new Set<string>();
  let index: VectorStoreIndex | null = null;

  try {
    // å°è¯•åŠ è½½ç°æœ‰ç´¢å¼•
    if (existsSync(join(outputDir, "vector_store.json"))) {
      console.log(`[build-indices]   ğŸ“š å‘ç°å·²æœ‰ç´¢å¼•ï¼Œå°è¯•åŠ è½½...`);
      
      try {
        // LlamaIndex TS 0.12+ ä¸­åˆå§‹åŒ–å·²æœ‰ç´¢å¼•çš„æ–¹æ³•
        index = await VectorStoreIndex.init({
          storageContext
        });
        
        // æå–æ‰€æœ‰å·²å­˜åœ¨çš„ docId
        // æ³¨æ„ï¼šdocStore.docs æ˜¯ä¸€ä¸ªå¯¹è±¡ï¼Œkey æ˜¯ id
        const docs = await storageContext.docStore.docs();
        Object.keys(docs).forEach(id => existingIds.add(id));
        
        console.log(`[build-indices]   âœ… å·²åŠ è½½ ${existingIds.size} æ¡å†å²æ•°æ®ï¼Œå°†è·³è¿‡é‡å¤é¡¹`);
      } catch (loadErr) {
        console.warn(`[build-indices]   âš ï¸ ç´¢å¼•æ–‡ä»¶å­˜åœ¨ä½†åŠ è½½å¤±è´¥ (å¯èƒ½æŸå)ï¼Œå°†é‡æ–°æ„å»º: ${loadErr}`);
        
        // ã€å…³é”®ä¿®å¤ã€‘å¦‚æœåŠ è½½å¤±è´¥ï¼ŒstorageContext å¯èƒ½å·²ç»å¤„äºä¸ä¸€è‡´çŠ¶æ€
        // å°¤å…¶æ˜¯ docStore.json åŠ è½½äº†ä¸€åŠã€‚
        // æˆ‘ä»¬éœ€è¦"é‡ç½®"å®ƒï¼Œæˆ–è€…è®©ä¸‹é¢çš„ä»£ç åœ¨ç©ºçš„çŠ¶æ€ä¸‹è¿è¡Œã€‚
        // ç”±äºæˆ‘ä»¬æ— æ³•è½»æ˜“é‡ç½® storageContext å¯¹è±¡ï¼Œæœ€å®‰å…¨çš„åšæ³•æ˜¯
        // å‘Šè¯‰åç»­é€»è¾‘ï¼šè¿™æ˜¯ä¸€ä¸ªå…¨æ–°çš„å¼€å§‹ï¼Œå¹¶æ¥å—å¯èƒ½çš„è¦†ç›–ã€‚
        
        index = null;
        existingIds.clear();
        
        // å¯é€‰ï¼šå¦‚æœæ–‡ä»¶å½»åº•åäº†ï¼Œåç»­å†™å…¥å¯èƒ½ä¼šå¤±è´¥å—ï¼Ÿ
        // å¦‚æœæ˜¯ JSON æ ¼å¼é”™è¯¯ï¼Œfs.writeFile ä¼šç›´æ¥è¦†ç›–å®ƒï¼Œé€šå¸¸æ²¡é—®é¢˜ã€‚
        // ä½†å¦‚æœæ–‡ä»¶ç³»ç»Ÿé”å®šï¼Œé‚£å°±æ²¡åŠæ³•äº†ã€‚
      }
    }
  } catch (e) {
    console.log(`[build-indices]   âš ï¸ åŠ è½½ç°æœ‰ç´¢å¼•å¤±è´¥ (å¯èƒ½æ˜¯é¦–æ¬¡æ„å»ºæˆ–æ–‡ä»¶æŸå): ${e}`);
    // å¦‚æœåŠ è½½å¤±è´¥ï¼Œå‡è®¾æ˜¯ä»å¤´å¼€å§‹
    index = null;
    existingIds.clear();
  }

  const totalBatches = Math.ceil(items.length / batchSize);
  console.log(`[build-indices] ${name}: å…± ${items.length} æ¡ï¼Œåˆ† ${totalBatches} æ‰¹å¤„ç† (æ¯æ‰¹ ${batchSize})`);
  console.log(`[build-indices] ${name}: chunkSize=${chunkSize}, concurrency=${concurrency}, persistEveryChunks=${persistEveryChunks}`);

  let insertedTotal = 0;
  const globalStart = Date.now();

  // ===== 2. åˆ†æ‰¹å¤„ç† =====
  for (let i = 0; i < items.length; i += batchSize) {
    const currentBatchNum = Math.floor(i / batchSize) + 1;
    const batchItems = items.slice(i, i + batchSize);
    
    // è½¬æ¢ä¸º Document (æ­¤æ—¶ç”Ÿæˆ ID)
    const docs = batchItems.map(docMapper);
    
    // è¿‡æ»¤æ‰å·²å­˜åœ¨çš„æ–‡æ¡£
    const newDocs = docs.filter(doc => !existingIds.has(doc.id_));
    
    if (newDocs.length === 0) {
      console.log(`[build-indices]   â­ï¸ ç¬¬ ${currentBatchNum}/${totalBatches} æ‰¹: å…¨éƒ¨ ${docs.length} æ¡å·²å­˜åœ¨ï¼Œè·³è¿‡`);
      continue;
    }
    
    console.log(`[build-indices]   æ­£åœ¨å¤„ç†ç¬¬ ${currentBatchNum}/${totalBatches} æ‰¹ (æ–°å¢ ${newDocs.length}/${docs.length} æ¡)...`);

    const batchStart = Date.now();

    let createdIndexThisBatch = false;
    let processedInBatch = 0;

    if (!index) {
      console.log(`[build-indices]   ğŸš€ åˆå§‹åŒ–ç´¢å¼•...`);
      const initialDocs = newDocs.slice(0, Math.min(chunkSize, newDocs.length));
      index = await VectorStoreIndex.fromDocuments(initialDocs, {
        storageContext
      });
      insertedTotal += initialDocs.length;
      for (const d of initialDocs) existingIds.add(d.id_);
      processedInBatch += initialDocs.length;
      createdIndexThisBatch = true;
    }

    const docsToInsert = createdIndexThisBatch ? newDocs.slice(Math.min(chunkSize, newDocs.length)) : newDocs;

    const totalChunks = Math.ceil(docsToInsert.length / chunkSize);
    let avgPerDocMs = 0;
    let completedDocsInBatch = processedInBatch;

    for (let chunkIdx = 0; chunkIdx < totalChunks; chunkIdx++) {
      const start = chunkIdx * chunkSize;
      const chunk = docsToInsert.slice(start, start + chunkSize);
      const chunkStart = Date.now();

      for (let j = 0; j < chunk.length; j += concurrency) {
        const sub = chunk.slice(j, j + concurrency);
        const insertedCounts = await Promise.all(sub.map(async (doc) => {
          try {
            await index!.insert(doc);
            existingIds.add(doc.id_);
            return 1;
          } catch (err) {
            console.error(`[build-indices]   âŒ æ’å…¥æ–‡æ¡£å¤±è´¥ (ID: ${doc.id_}):`, err);
            return 0;
          }
        }));
        insertedTotal += insertedCounts.reduce<number>((a, b) => a + b, 0);
      }

      const chunkElapsed = Date.now() - chunkStart;
      const perDoc = chunkElapsed / Math.max(1, chunk.length);
      avgPerDocMs = avgPerDocMs === 0 ? perDoc : avgPerDocMs * 0.8 + perDoc * 0.2;

      completedDocsInBatch += chunk.length;

      const remainingInBatch = newDocs.length - completedDocsInBatch;
      const etaMs = avgPerDocMs * remainingInBatch;
      const elapsedTotal = Date.now() - globalStart;

      process.stdout.write(
        `\r[build-indices]   æ‰¹ ${currentBatchNum}/${totalBatches} Â· ${completedDocsInBatch}/${newDocs.length} Â· æ€»æ’å…¥ ${insertedTotal} Â· æœ¬æ‰¹ETA ${formatDurationMs(etaMs)} Â· æ€»è€—æ—¶ ${formatDurationMs(elapsedTotal)}        `
      );

      if ((chunkIdx + 1) % persistEveryChunks === 0 || chunkIdx === totalChunks - 1) {
        if (docStoreAny?.kvStore?.persist) {
          await docStoreAny.kvStore.persist(docStorePath);
        } else {
          await storageContext.docStore.persist(docStorePath);
        }
        if (indexStoreAny?.kvStore?.persist) {
          await indexStoreAny.kvStore.persist(indexStorePath);
        } else {
          await storageContext.indexStore.persist(indexStorePath);
        }
        if (vectorStoreAny?.persist) await vectorStoreAny.persist(vectorStorePath);
      }
    }

    if (totalChunks === 0) {
      if (docStoreAny?.kvStore?.persist) {
        await docStoreAny.kvStore.persist(docStorePath);
      } else {
        await storageContext.docStore.persist(docStorePath);
      }
      if (indexStoreAny?.kvStore?.persist) {
        await indexStoreAny.kvStore.persist(indexStorePath);
      } else {
        await storageContext.indexStore.persist(indexStorePath);
      }
      if (vectorStoreAny?.persist) await vectorStoreAny.persist(vectorStorePath);
    }

    process.stdout.write("\n");
    console.log(`[build-indices]   âœ… ç¬¬ ${currentBatchNum} æ‰¹å®Œæˆ (è€—æ—¶: ${formatDurationMs(Date.now() - batchStart)})`);
    
    // æ‰‹åŠ¨è§¦å‘åƒåœ¾å›æ”¶ (å¦‚æœå¯ç”¨)
    if (global.gc) {
        global.gc();
    }
  }
  
  // ç¡®ä¿æœ€åä¿å­˜
  // åœ¨æŸäº›ç‰ˆæœ¬ä¸­éœ€è¦æ˜¾å¼è°ƒç”¨ï¼Œä½† storageContextFromDefaults ç»‘å®šçš„æ–‡ä»¶ç³»ç»Ÿé€šå¸¸ä¼šåœ¨æ›´æ–°æ—¶å†™å…¥
  // æˆ–è€… index å¯¹è±¡æœ‰ persist æ–¹æ³•? 
  // index.storageContext.docStore.persist()
  // ç®€å•èµ·è§ï¼Œæˆ‘ä»¬ä¿¡ä»»åº“çš„è¡Œä¸ºã€‚
  console.log(`[build-indices] âœ… ${name} ç´¢å¼•æ„å»ºå®Œæˆï¼Œå·²ä¿å­˜è‡³: ${outputDir}`);
}

/**
 * æ„å»ºé‡‘å¥åº“ç´¢å¼•
 */
async function buildQuotesIndex(options?: { chunkSize?: number; concurrency?: number; persistEveryChunks?: number }): Promise<void> {
  console.log("\n[build-indices] === æ„å»ºé‡‘å¥åº“ç´¢å¼• ===");

  const jsonlFile = join(DATA_DIR, "golden_sentences.jsonl");
  if (!existsSync(jsonlFile)) {
    console.error(`[build-indices] âŒ æ–‡ä»¶ä¸å­˜åœ¨: ${jsonlFile}`);
    return;
  }

  const data = loadJSONL(jsonlFile);
  const outputDir = join(INDICES_DIR, "golden_quotes");

  await buildIndexInBatches(
    "é‡‘å¥åº“",
    data,
    1000,
    outputDir,
    (item) => {
      const doc = new Document({
        text: item.content,
        metadata: {
          id: item.id,
          quote_type: item.quote_type || "",
          quality_score: item.quality_score?.overall || 0,
          source_title: item.source_title || "",
          url: item.source_url || "",
          category: item.category || ""
        }
      });
      if (item.id) doc.id_ = String(item.id);
      return doc;
    },
    options
  );
}

/**
 * æ„å»ºæ–‡ç« åº“ç´¢å¼•
 */
async function buildArticlesIndex(options?: { chunkSize?: number; concurrency?: number; persistEveryChunks?: number }): Promise<void> {
  console.log("\n[build-indices] === æ„å»ºæ–‡ç« åº“ç´¢å¼• ===");

  const articlesDir = join(DATA_DIR, "articles");
  if (!existsSync(articlesDir)) {
    console.error(`[build-indices] âŒ ç›®å½•ä¸å­˜åœ¨: ${articlesDir}`);
    return;
  }

  const files = readdirSync(articlesDir).filter(f => f.endsWith(".jsonl"));
  if (files.length === 0) {
    console.error(`[build-indices] âŒ æœªæ‰¾åˆ° JSONL æ–‡ä»¶`);
    return;
  }

  console.log(`[build-indices] åŠ è½½ ${files.length} ä¸ªæ–‡ä»¶...`);
  
  let allArticles: any[] = [];
  for (const file of files) {
    const filePath = join(articlesDir, file);
    const articles = loadJSONL(filePath);
    // é™„åŠ æºæ–‡ä»¶ååˆ°æ¯ä¸ªæ–‡ç« å¯¹è±¡ï¼Œä»¥ä¾¿åœ¨ mapper ä¸­ä½¿ç”¨
    articles.forEach(a => a._source_file = file);
    allArticles.push(...articles);
  }

  const outputDir = join(INDICES_DIR, "articles");

  await buildIndexInBatches(
    "æ–‡ç« åº“",
    allArticles,
    500,
    outputDir,
    (item) => {
      const text = `æ ‡é¢˜ï¼š${item.title}\n\n${item.content}`;
      const doc = new Document({
        text,
        metadata: {
          title: item.title || "",
          publish_time: item.publish_time || "",
          url: item.url || "",
          source_file: item._source_file || ""
        }
      });
      // ä½¿ç”¨ URL æˆ– æ ‡é¢˜+æ–‡ä»¶å ä½œä¸ºç¡®å®šæ€§ ID
      // ä¼˜å…ˆä½¿ç”¨ URLï¼Œå› ä¸ºå®ƒæ˜¯å”¯ä¸€çš„ï¼›å¦‚æœæ²¡æœ‰ï¼Œåˆ™ä½¿ç”¨ title + source_file çš„å“ˆå¸Œ
      // è¿™é‡Œç®€å•æ‹¼æ¥ï¼Œå› ä¸º Document ID åªæ˜¯ä¸ªå­—ç¬¦ä¸²
      if (item.url) {
        doc.id_ = item.url;
      } else {
        // ç®€å•æ¸…ç†æ–‡ä»¶å
        const cleanTitle = (item.title || "").replace(/[^a-zA-Z0-9\u4e00-\u9fa5]/g, "");
        const cleanSource = (item._source_file || "").replace(/[^a-zA-Z0-9]/g, "");
        doc.id_ = `${cleanTitle}_${cleanSource}`;
      }
      return doc;
    },
    options
  );
}

/**
 * æ„å»ºæ ‡é¢˜åº“ç´¢å¼• (ç”Ÿæˆ JSONL æ–‡ä»¶)
 */
async function buildTitlesIndex(): Promise<void> {
  console.log("\n[build-indices] === æ„å»ºæ ‡é¢˜åº“ (ç”Ÿæˆ article_titles.jsonl) ===");

  const articlesDir = join(DATA_DIR, "articles");
  if (!existsSync(articlesDir)) {
    console.error(`[build-indices] âŒ ç›®å½•ä¸å­˜åœ¨: ${articlesDir}`);
    return;
  }

  const files = readdirSync(articlesDir).filter(f => f.endsWith(".jsonl"));
  if (files.length === 0) {
    console.error(`[build-indices] âŒ æœªæ‰¾åˆ° JSONL æ–‡ä»¶`);
    return;
  }

  let titleCount = 0;
  const titleLines: string[] = [];

  for (const file of files) {
    const filePath = join(articlesDir, file);
    const articles = loadJSONL(filePath);

    for (const article of articles) {
      if (!article.title) continue;

      const titleRecord = {
        title: article.title,
        source_file: file
      };
      
      titleLines.push(JSON.stringify(titleRecord));
      titleCount++;
    }
  }

  const outputFile = join(DATA_DIR, "article_titles.jsonl");
  writeFileSync(outputFile, titleLines.join("\n"), "utf-8");

  console.log(`[build-indices] âœ… æ ‡é¢˜åº“ç”Ÿæˆå®Œæˆ: ${titleCount} æ¡è®°å½•`);
  console.log(`[build-indices]    å·²ä¿å­˜è‡³: ${outputFile}`);
}

/**
 * ä¸»å‡½æ•°
 */
async function main() {
  const args = process.argv.slice(2);
  const target = args.find(a => !a.startsWith("-")); // 'quotes' | 'articles' | 'titles' | undefined
  const chunkSize = parseNumberArg(args, "--chunk", 10);
  const concurrency = parseNumberArg(args, "--concurrency", 1);
  const persistEveryChunks = args.includes("--persist-every") ? parseNumberArg(args, "--persist-every", 1) : undefined;
  const runtimeOptions: { chunkSize?: number; concurrency?: number; persistEveryChunks?: number } = {
    chunkSize,
    concurrency,
    persistEveryChunks
  };

  console.log("[build-indices] å¼€å§‹æ„å»ºå‘é‡ç´¢å¼•...\n");
  console.log(`[build-indices] æ•°æ®ç›®å½•: ${DATA_DIR}`);
  console.log(`[build-indices] ç´¢å¼•ç›®å½•: ${INDICES_DIR}`);
  console.log(`[build-indices] åµŒå…¥æ¨¡å‹: æœ¬åœ°æ¨¡å‹ (local_models)`);
  if (target) {
    console.log(`[build-indices] ğŸ¯ ä»…æ„å»ºç›®æ ‡: ${target}`);
  }

  const startTime = Date.now();

  try {
    // æ„å»ºé‡‘å¥åº“ç´¢å¼•
    if (!target || target === 'quotes') {
      await buildQuotesIndex(runtimeOptions);
    }

    // æ„å»ºæ–‡ç« åº“ç´¢å¼•
    if (!target || target === 'articles') {
      await buildArticlesIndex(runtimeOptions);
    }

    // æ„å»ºæ ‡é¢˜åº“ç´¢å¼• (éå‘é‡ï¼Œä»…ç”Ÿæˆ JSONL)
    if (!target || target === 'titles') {
      await buildTitlesIndex();
    }

    const elapsed = ((Date.now() - startTime) / 1000).toFixed(1);
    console.log(`\n[build-indices] ğŸ‰ ç´¢å¼•æ„å»ºå®Œæˆ! (æ€»è€—æ—¶: ${elapsed}ç§’)`);

  } catch (error) {
    console.error(`\n[build-indices] âŒ æ„å»ºå¤±è´¥:`, error);
    process.exit(1);
  }
}

// è¿è¡Œ
main();
